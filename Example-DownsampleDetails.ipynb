{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexible unsupervised binary change detection algorithm identifies phase transitions in continuous image streams\n",
    "\n",
    "### Paul Chao <sup>1</sup> , Xianghui Xiao <sup>2</sup>, and Ashwin J. Shahani <sup>1</sup> \n",
    "\n",
    "<sup>1</sup> University of Michigan, Ann Arbor\n",
    "<sup>2</sup> Brookhaven National Laboratory, Upton, NY\n",
    "\n",
    "This jupyter notebook will aim to elaborate on the effect of downsampling and the change point detection. Download data from [Dropbox](https://www.dropbox.com/sh/33jvy07mds3tkee/AAAze7eCLUJi-P-cKe7Il2T8a?dl=0) and place in the same folder as this notebook to run this example for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions to process the examples\n",
    "from sinogram_functions import prepare_sinogram, save_sino, digitizetolevels, analyze_sinogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study #1: Formation of quasicrystal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice 650: visible at t=40,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\pchao\\Documents\\000_Sinogram\\Example\\For github\\data_QC_650.npy\n"
     ]
    }
   ],
   "source": [
    "#Specify path to the example file, this corresponds to the 650th slice in the final volume. \n",
    "filename = 'data_QC_650.npy'\n",
    "filepath = os.path.join(sys.path[0], filename)\n",
    "\n",
    "# Import sinogram\n",
    "sinogram_orig = np.load(filepath)\n",
    "print('File: ' + filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Downsample Scale: 1\n",
      " *** Clustering Results\n",
      "Critical point: 42729\n",
      "Range of critical point (60% threshold): (42211, 43556)\n",
      "Range of critical point (70% threshold): (41569, 44757)\n",
      "Range of critical point (80% threshold): (40941, 47084)\n",
      " ** Time to analyze: 31.35 seconds\n",
      " Downsample Scale: 1\n",
      " In the downsampled dataset, time of critical point identified at: 42729 [Full data: 42729]\n",
      " \n",
      " Downsample Scale: 5\n",
      " *** Clustering Results\n",
      "Critical point: 8465\n",
      "Range of critical point (60% threshold): (8356, 8582)\n",
      "Range of critical point (70% threshold): (8263, 8852)\n",
      "Range of critical point (80% threshold): (8147, 9435)\n",
      " ** Time to analyze: 3.82 seconds\n",
      " Downsample Scale: 5\n",
      " In the downsampled dataset, time of critical point identified at: 8465 [Full data: 42325]\n",
      " \n",
      " Downsample Scale: 10\n",
      " *** Clustering Results\n",
      "Critical point: 4232\n",
      "Range of critical point (60% threshold): (4181, 4287)\n",
      "Range of critical point (70% threshold): (4135, 4439)\n",
      "Range of critical point (80% threshold): (4088, 4755)\n",
      " ** Time to analyze: 1.98 seconds\n",
      " Downsample Scale: 10\n",
      " In the downsampled dataset, time of critical point identified at: 4232 [Full data: 42320]\n",
      " \n",
      " Downsample Scale: 20\n",
      " *** Clustering Results\n",
      "Critical point: 2116\n",
      "Range of critical point (60% threshold): (2092, 2142)\n",
      "Range of critical point (70% threshold): (2069, 2220)\n",
      "Range of critical point (80% threshold): (2047, 2384)\n",
      " ** Time to analyze: 1.37 seconds\n",
      " Downsample Scale: 20\n",
      " In the downsampled dataset, time of critical point identified at: 2116 [Full data: 42320]\n"
     ]
    }
   ],
   "source": [
    "period = 2000\n",
    "downsamplescale_list = [1, 5, 10, 20]\n",
    "\n",
    "for downsamplescale in downsamplescale_list:\n",
    "    print(' ')\n",
    "    print(' Downsample Scale: ' + str(downsamplescale))\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prepare the sinogram (i.e. background normalization)\n",
    "    sinogram = prepare_sinogram(sinogram_orig, period=period, downsamplescale=downsamplescale, numLiq=3, keepLiq=True)\n",
    "\n",
    "    # Save the processed results\n",
    "    #save_sino(sinogram, 'sino_cs1.png')\n",
    "\n",
    "    # descretize the data \n",
    "    sinogram = digitizetolevels(sinogram)\n",
    "\n",
    "    # Perform analysis\n",
    "\n",
    "    critical_pt = analyze_sinogram(sinogram, period//downsamplescale, save=False)\n",
    "    print(' ** Time to analyze: {:0.2f} seconds'.format(time.time()-start_time))\n",
    "\n",
    "    print(' Downsample Scale: ' + str(downsamplescale))\n",
    "    print(' In the downsampled dataset, time of critical point identified at: ' + str(critical_pt[0]) + ' [Full data: ' + str(critical_pt[0]*downsamplescale) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study #2: Formation of primary silicon in a chemically-modified alloy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice 50: visible at t=52500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\pchao\\Documents\\000_Sinogram\\Example\\For github\\data_AlSiSr_50.npy\n"
     ]
    }
   ],
   "source": [
    "#Specify path to the example file, this corresponds to the 50th slice in the final volume. \n",
    "filename = 'data_AlSiSr_50.npy'\n",
    "filepath = os.path.join(sys.path[0], filename)\n",
    "\n",
    "#Import and process sinogram\n",
    "sinogram_orig = np.load(filepath)\n",
    "print('File: ' + filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Downsample Scale: 1\n",
      " *** Clustering Results\n",
      "Critical point: 50803\n",
      "Range of critical point (60% threshold): (49712, 56391)\n",
      "Range of critical point (70% threshold): (48028, 60148)\n",
      "Range of critical point (80% threshold): (9328, 61666)\n",
      " ** Time to analyze: 36.06 seconds\n",
      " Downsample Scale: 1\n",
      " In the downsampled dataset, time of critical point identified at: 50803 [Full data: 50803]\n",
      " \n",
      " Downsample Scale: 5\n",
      " *** Clustering Results\n",
      "Critical point: 10043\n",
      "Range of critical point (60% threshold): (9793, 11156)\n",
      "Range of critical point (70% threshold): (9403, 11333)\n",
      "Range of critical point (80% threshold): (1133, 12192)\n",
      " ** Time to analyze: 4.70 seconds\n",
      " Downsample Scale: 5\n",
      " In the downsampled dataset, time of critical point identified at: 10043 [Full data: 50215]\n",
      " \n",
      " Downsample Scale: 10\n",
      " *** Clustering Results\n",
      "Critical point: 5445\n",
      "Range of critical point (60% threshold): (5139, 5580)\n",
      "Range of critical point (70% threshold): (4730, 5665)\n",
      "Range of critical point (80% threshold): (559, 6082)\n",
      " ** Time to analyze: 2.39 seconds\n",
      " Downsample Scale: 10\n",
      " In the downsampled dataset, time of critical point identified at: 5445 [Full data: 54450]\n",
      " \n",
      " Downsample Scale: 20\n",
      " *** Clustering Results\n",
      "Critical point: 2741\n",
      "Range of critical point (60% threshold): (2571, 2793)\n",
      "Range of critical point (70% threshold): (2368, 2834)\n",
      "Range of critical point (80% threshold): (2015, 3044)\n",
      " ** Time to analyze: 1.66 seconds\n",
      " Downsample Scale: 20\n",
      " In the downsampled dataset, time of critical point identified at: 2741 [Full data: 54820]\n"
     ]
    }
   ],
   "source": [
    "period = 3000\n",
    "downsamplescale_list = [1, 5, 10, 20]\n",
    "\n",
    "for downsamplescale in downsamplescale_list:\n",
    "    print(' ')\n",
    "    print(' Downsample Scale: ' + str(downsamplescale))\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Prepare the sinogram (i.e. background normalization)\n",
    "    sinogram = prepare_sinogram(sinogram_orig, period=period, downsamplescale=downsamplescale, numLiq=3, keepLiq=True)\n",
    "\n",
    "    # Save the processed results\n",
    "    #save_sino(sinogram, 'sino_cs1.png')\n",
    "\n",
    "    # descretize the data \n",
    "    sinogram = digitizetolevels(sinogram)\n",
    "\n",
    "    # Perform analysis\n",
    "\n",
    "    critical_pt = analyze_sinogram(sinogram, period//downsamplescale, save=False)\n",
    "    print(' ** Time to analyze: {:0.2f} seconds'.format(time.time()-start_time))\n",
    "\n",
    "    print(' Downsample Scale: ' + str(downsamplescale))\n",
    "    print(' In the downsampled dataset, time of critical point identified at: ' + str(critical_pt[0]) + ' [Full data: ' + str(critical_pt[0]*downsamplescale) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print-outs for both datasets show similar analysis speed up through downsampling: From no downsampling (approximately 30 seconds) to downsampling by a factor to 20 (approximately 1.5 seconds). The identified critical point is within a period of the actual critical point and is an excellent starting point to begin time-consuming and computationally-intensive tomographic recontructions to visualize the in-situ phenomena studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
